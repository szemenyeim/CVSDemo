{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deep Learning.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"3Z4P4Sx6fcA4","colab_type":"text"},"cell_type":"markdown","source":["# Deep Learning Demo\n","In this demo you can learn how to use deep neural netowrks to classify images\n","## Installing Requirements"]},{"metadata":{"id":"CY4tNVi0OPAJ","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install torch torchvision"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tmKpGnX4qmhw","colab_type":"text"},"cell_type":"markdown","source":["## Creating a Neural network model\n","### Define Convolutional block"]},{"metadata":{"id":"tZgVwVxiqvAI","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","# Convolutional module (Conv+ReLU+BatchNorm)\n","class Conv(nn.Module):\n","    \n","    # Constructor gets in and output channels and stride\n","    def __init__(self, in_channels, channels, stride=1):\n","        super(Conv, self).__init__()\n","        \n","        # Create 2D Convolution (3x3)\n","        self.conv = nn.Conv2d(in_channels, channels, kernel_size=3, stride=stride, padding=1, bias=False)\n","        \n","        # Create Batchnorm\n","        self.bn = nn.BatchNorm2d(channels)\n","        \n","    # Overwrite forward\n","    def forward(self,x):\n","        # Call the layers in the proper order\n","        return self.bn(torch.relu(self.conv(x)))\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"NMz0b5m_rNsm","colab_type":"text"},"cell_type":"markdown","source":["### Create neural network"]},{"metadata":{"id":"usIMgRj5rQR6","colab_type":"code","colab":{}},"cell_type":"code","source":["class ConvNet(nn.Module):\n","    \n","    # Constructor gets channel number of the image and the first filter\n","    def __init__(self, base_channels=16, in_channels=3, num_classes=10):\n","        super(ConvNet, self).__init__()\n","        \n","        # First two filters\n","        self.c11 = Conv(in_channels, base_channels)\n","        self.c12 = Conv(base_channels, base_channels)\n","        \n","        # Downscale using strided convolution and expand channels\n","        self.d1 = Conv(base_channels, base_channels*2, 2)\n","        \n","        # Repeat this 4 times\n","        self.c21 = Conv(base_channels*2, base_channels*2)\n","        self.c22 = Conv(base_channels*2, base_channels*2)\n","        \n","        self.d2 = Conv(base_channels*2, base_channels*4, 2)\n","        \n","        self.c31 = Conv(base_channels*4, base_channels*4)\n","        self.c32 = Conv(base_channels*4, base_channels*4)\n","        \n","        self.d3 = Conv(base_channels*4, base_channels*8, 2)\n","        \n","        self.c41 = Conv(base_channels*8, base_channels*8)\n","        self.c42 = Conv(base_channels*8, base_channels*8)\n","        \n","        self.d4 = Conv(base_channels*8, base_channels*16, 2)\n","        \n","        self.c51 = Conv(base_channels*16, base_channels*16)\n","        self.c52 = Conv(base_channels*16, base_channels*16)\n","        \n","        # Input image is 32x32 -> after 5 downscaling the activation map is 1x1\n","        self.d5 = Conv(base_channels*16, base_channels*32, 2)\n","        \n","        # Classifier is a normal 1x1 convolution that produces num_classes class scores\n","        # This layer does not have BatchNorm of ReLU\n","        self.classifier = nn.Conv2d(base_channels*32,num_classes,kernel_size=1)\n","        \n","    def forward(self,x):\n","        # Class all the layers\n","        x = self.d1(self.c12(self.c11(x)))\n","        x = self.d2(self.c22(self.c21(x)))\n","        x = self.d3(self.c32(self.c31(x)))\n","        x = self.d4(self.c42(self.c41(x)))\n","        x = self.d5(self.c52(self.c51(x)))\n","        \n","        # Squeeze removes dimensions that have only 1 element\n","        # Output of the conv layer is (batch_size x num_classes x 1 x 1)\n","        # After squeeze is becomes (batch_size x num_classes)\n","        return torch.squeeze(self.classifier(x))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tR7Bgu1dsh7E","colab_type":"text"},"cell_type":"markdown","source":["## Setup Learning\n","### Check GPU Availability"]},{"metadata":{"id":"M-pkDDdsst12","colab_type":"code","colab":{}},"cell_type":"code","source":["haveCuda = torch.cuda.is_available()\n","print(haveCuda)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dba1bJu1s5kn","colab_type":"text"},"cell_type":"markdown","source":["### Data Augmentation"]},{"metadata":{"id":"SNu9i9_Vs8Jt","colab_type":"code","colab":{}},"cell_type":"code","source":["from torchvision import transforms\n","\n","# Necessary transformations: conversion to PyTorch Tensor and normalization\n","# Normalization is performed with channels-wise means and variances computed on ImageNet\n","transform_val = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.49139968, 0.48215827, 0.44653124),\n","                         (0.24703233, 0.24348505, 0.26158768))\n","])\n","\n","# Train database transform includes data augmentation\n","transform = transforms.Compose([\n","    # Random 32x32 crops (with 4-wide zero padding - this is needed because the \n","    # input is 32x32 so we can't crop a 32x32 region out of it without padding)\n","    transforms.RandomCrop(32,padding=4),\n","    # Flips horizontally with p=0.5\n","    transforms.RandomHorizontalFlip(),\n","    # Random perturbance of brightness, contrast and color\n","    transforms.ColorJitter(brightness=0.3,contrast=0.3,saturation=0.3,hue=0.2),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.49139968, 0.48215827, 0.44653124),\n","                         (0.24703233, 0.24348505, 0.26158768))\n","])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aJTy9SputIRa","colab_type":"text"},"cell_type":"markdown","source":["### Datasets"]},{"metadata":{"id":"ihWaGVQ_tJzv","colab_type":"code","colab":{}},"cell_type":"code","source":["import torchvision\n","\n","# Trainsets automatically download the dataset if not present\n","trainSet = torchvision.datasets.CIFAR10(root=\"./data\", download=True,\n","                                        train=True, transform=transform)\n","testSet = torchvision.datasets.CIFAR10(root=\"./data\", download=True,\n","                                       train=False, transform=transform_val)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mDVbsgJdtWaB","colab_type":"text"},"cell_type":"markdown","source":["### Dataloaders"]},{"metadata":{"id":"TENUBRgjtYHS","colab_type":"code","colab":{}},"cell_type":"code","source":["# Dataloaders are responsible for giving random (if shuffle is true) minibatches\n","trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=128, shuffle=True)\n","testLoader = torch.utils.data.DataLoader(testSet, batch_size=128, shuffle=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dtm_dt9stiRH","colab_type":"text"},"cell_type":"markdown","source":["### Create Network"]},{"metadata":{"id":"PWih_K8etkFX","colab_type":"code","colab":{}},"cell_type":"code","source":["# Instantiate network and convert it to CUDA\n","def createNet():\n","    net = ConvNet()\n","    if haveCuda:\n","        net = net.cuda()\n","    return net"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oYGtGSFEts0P","colab_type":"text"},"cell_type":"markdown","source":["### Create Loss"]},{"metadata":{"id":"uA-0-OfatuVC","colab_type":"code","colab":{}},"cell_type":"code","source":["# We use cros entropy, since CIFAR10 is a classification set\n","def createLoss():\n","    return nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TAjRulJftv71","colab_type":"text"},"cell_type":"markdown","source":["### Create optimizer"]},{"metadata":{"id":"J1fXbFE2tzBg","colab_type":"code","colab":{}},"cell_type":"code","source":["from torch import optim\n","\n","# Stochastic Gradient Descent (SGD) optimizer with Nesterov momentum and 0.1 learning rate\n","# Weight decay is the relative weight of the L2 regularization term\n","def createOptimizer():\n","    return optim.SGD(net.parameters(), lr=1e-1, momentum=0.9, nesterov=True, weight_decay=1e-4)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RtfncjnFt5KJ","colab_type":"text"},"cell_type":"markdown","source":["### Create Learning Rate Scheduler"]},{"metadata":{"id":"r8bD4aHJt9Gc","colab_type":"code","colab":{}},"cell_type":"code","source":["# Run for 50 epochs - 1 epoch means the networks sees every training image once\n","numEpoch = 50\n","\n","# Cosine annealing learning rate scheduler - in 50 epochs the lr will become 0.01\n","def createScheduler():\n","    return optim.lr_scheduler.CosineAnnealingLR(optimizer,numEpoch,eta_min=1e-2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"22Poq4wouJp7","colab_type":"text"},"cell_type":"markdown","source":["## Epoch Functions\n","### Progress bar"]},{"metadata":{"id":"8DsSjcaTukCC","colab_type":"code","colab":{}},"cell_type":"code","source":["from IPython.display import HTML, display\n","\n","def progress(value, max=100):\n","    return HTML(\"\"\"\n","        <progress\n","            value='{value}'\n","            max='{max}',\n","            style='width: 100%'\n","        >\n","            {value}\n","        </progress>\n","    \"\"\".format(value=value, max=max))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"I9oKNc4JukLT","colab_type":"text"},"cell_type":"markdown","source":["### Train"]},{"metadata":{"id":"EGwmgbUpuQXf","colab_type":"code","colab":{}},"cell_type":"code","source":["# Function for training a single epch\n","def train(epoch):\n","\n","    # variables for loss\n","    running_loss = 0.0\n","    correct = 0.0\n","    total = 0\n","\n","    # set the network to train (for batchnorm and dropout)\n","    net.train()\n","\n","    # Create progress bar\n","    bar = display(progress(0, len(trainLoader)), display_id=True)\n","\n","    # data will contain one minibatch of images and correcponding labels\n","    # When the iteration is finished we have seen every training image once\n","    for i, data in enumerate(trainLoader, 0):\n","        # get the inputs\n","        inputs, labels = data\n","\n","        # Convert to cuda\n","        if haveCuda:\n","            inputs, labels = inputs.cuda(), labels.cuda()\n","\n","        # Clear any previous gradients\n","        optimizer.zero_grad()\n","\n","        # Forward\n","        outputs = net(inputs)\n","        # Loss\n","        loss = criterion(outputs, labels)\n","        # Backpropagation\n","        loss.backward()\n","        # Gradient method\n","        optimizer.step()\n","\n","        # Do not include these steps in the computational graph\n","        with torch.no_grad():\n","            # Accumulate loss\n","            running_loss += loss.item()\n","            # Get indices of the largest goodness values\n","            _, predicted = torch.max(outputs, 1)\n","            # Count how many of the predictions equal the labels\n","            correct += predicted.eq(labels).sum().item()\n","            # Accumulate number of total images seen\n","            total += labels.size(0)\n","\n","        # Progress bar\n","        bar.update(progress(i+1, len(trainLoader)))\n","\n","    # return loss and accuracy\n","    tr_loss = running_loss / i\n","    tr_corr = correct / total * 100\n","    print(\"Train epoch %d loss: %.3f correct: %.2f\" % (epoch + 1, running_loss / i, tr_corr))\n","    return tr_loss,tr_corr"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ne92UroivFGo","colab_type":"text"},"cell_type":"markdown","source":["### Validation"]},{"metadata":{"id":"e5mrlwmhvGcF","colab_type":"code","colab":{}},"cell_type":"code","source":["# Function for validating a single epch\n","def val(epoch):\n","\n","    # variables for loss\n","    running_loss = 0.0\n","    correct = 0.0\n","    total = 0\n","\n","    # set the network to eval  (for batchnorm and dropout)\n","    net.eval()\n","\n","    # Create progress bar\n","    bar = display(progress(0, len(testLoader)), display_id=True)\n","\n","    for i, data in enumerate(testLoader, 0):\n","        # get the inputs\n","        inputs, labels = data\n","\n","        # Convert to cuda\n","        if haveCuda:\n","            inputs, labels = inputs.cuda(), labels.cuda()\n","\n","        # Do not include these steps in the computational graph\n","        with torch.no_grad():\n","            # Forward\n","            outputs = net(inputs)\n","            # Compute loss\n","            loss = criterion(outputs, labels)\n","\n","            # Compute statistics, just like before\n","            running_loss += loss.item()\n","            _, predicted = torch.max(outputs, 1)\n","            correct += predicted.eq(labels).sum().item()\n","            total += labels.size(0)\n","\n","        bar.update(progress(i+1, len(testLoader)))\n","\n","    # return loss and accuracy\n","    val_loss = running_loss / i\n","    val_corr = correct / total * 100\n","    print(\"Test epoch %d loss: %.3f correct: %.2f\" % (epoch + 1, running_loss / i, val_corr))\n","    return val_loss,val_corr"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TyOMdVD6vs7D","colab_type":"text"},"cell_type":"markdown","source":["## Main Loop"]},{"metadata":{"id":"hGXuD1tTvveX","colab_type":"code","colab":{}},"cell_type":"code","source":["# Containers for losses and accuracies for every epoch\n","train_accs = []\n","train_losses = []\n","val_accs = []\n","val_losses = []\n","\n","# Best validation accuracy\n","best_acc = 0\n","\n","# Set pseudo-random generator seeds to make multiple runs comparable\n","torch.manual_seed(1)\n","if haveCuda:\n","    torch.cuda.manual_seed(1)\n","\n","# Create net, criterion, optimizer and scheduler\n","# This needs to be done after setting the random seed, \n","# so that the random initialization would be the same\n","net = createNet()\n","criterion = createLoss()\n","optimizer = createOptimizer()\n","scheduler = createScheduler()\n","\n","# For numEpoch epochs\n","for epoch in range(numEpoch):\n","    \n","    # The with the LR scheduler\n","    scheduler.step()\n","    \n","    # Train\n","    loss,acc = train(epoch)\n","    train_accs.append(acc)\n","    train_losses.append(loss)\n","    \n","    # Validate\n","    loss,acc = val(epoch)\n","    val_accs.append(acc)\n","    val_losses.append(loss)\n","    \n","    # If the current model is better, than the previous best, save it\n","    if acc > best_acc:\n","        print(\"Best Model, Saving\")\n","        best_acc = acc\n","        torch.save(net,\"./data/model.pth\")\n","        \n","\n","\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"k_Rn8t63mMyE","colab_type":"text"},"cell_type":"markdown","source":["### Plot graphs"]},{"metadata":{"id":"5fD5twERTLHj","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# X coordinate for plotting\n","x = np.arange(numEpoch)\n","\n","plt.figure(figsize=(20,10))\n","\n","# Train is red, validation is blue\n","plt.subplot(1,2,1)\n","plt.plot(x,train_accs,'r')\n","plt.plot(x,val_accs,'b')\n","\n","plt.subplot(1,2,2)\n","plt.plot(x,train_losses,'r')\n","plt.plot(x,val_losses,'b')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nRyOcLuRvnKi","colab_type":"text"},"cell_type":"markdown","source":["### Visualize results"]},{"metadata":{"id":"shz50Jk3vqZ5","colab_type":"code","colab":{}},"cell_type":"code","source":["# Get a minibatch from the test loader and convert to cuda\n","inputs, labels = next(iter(testLoader))\n","if haveCuda:\n","    inputs, labels = inputs.cuda(), labels.cuda()\n","\n","# forward\n","outputs = net(inputs)\n","\n","# Get predicted class indices\n","_, predicted = torch.max(outputs, 1)\n","\n","# Values used for normalization\n","mean = torch.Tensor((0.49139968, 0.48215827, 0.44653124)).unsqueeze(1).unsqueeze(1)\n","std = torch.Tensor((0.24703233, 0.24348505, 0.26158768)).unsqueeze(1).unsqueeze(1)\n","\n","# Class names\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","# List of subplots - we'll use 16 images\n","f, axarr = plt.subplots(2, 8,figsize=(20, 5))\n","\n","# For every image-prediction pair\n","for i,(img,pred) in enumerate(zip(inputs,predicted)):\n","    # undo the normalization\n","    img_rescaled = img.cpu() * std + mean\n","    \n","    # Get predicted class name\n","    name = classes[pred.cpu().item()]\n","    \n","    # Permutation needed because in PyTorch the channel dimension comes first,\n","    # but in numpy and opencv it comes last (3x32x32) -> (32x32x3)\n","    axarr[i//8,i%8].imshow(img_rescaled.permute(1,2,0))\n","    \n","    # Set title to class name\n","    axarr[i//8,i%8].set_title(name)\n","    \n","    # Hide grid lines\n","    axarr[i//8,i%8].grid(False)\n","    \n","    # Hide axes ticks\n","    axarr[i//8,i%8].set_xticks([])\n","    axarr[i//8,i%8].set_yticks([])\n","    \n","    # Only do the first 16\n","    if i == 15:\n","        break"],"execution_count":0,"outputs":[]}]}