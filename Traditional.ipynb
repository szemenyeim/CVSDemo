{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Traditional.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/szemenyeim/CVSDemo/blob/master/Traditional.ipynb","timestamp":1555064723730}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"BbjVh4MgEkCr","colab_type":"text"},"cell_type":"markdown","source":["# Computer Vision Systems\n","## Traditional Vision Demo\n","In this notebook we demonstrate the usage of simple computer vision algorithms using OpenCV and Python\n","\n","### Installing OpenCV"]},{"metadata":{"id":"Y23G-oQnDaT1","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install opencv-python"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zZENQMwggQlT","colab_type":"text"},"cell_type":"markdown","source":["### Downloading images"]},{"metadata":{"id":"x3OMOLOWgVeW","colab_type":"code","colab":{}},"cell_type":"code","source":["!wget http://3dmr.iit.bme.hu/edu/DL/Downloads.zip\n","!unzip Downloads.zip\n","!rm Downloads.zip"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aWwDlU5sg2b8","colab_type":"text"},"cell_type":"markdown","source":["## Image basics\n","### Read and dislay"]},{"metadata":{"id":"osWePH8sg_mG","colab_type":"code","colab":{}},"cell_type":"code","source":["#OpenCV\n","import cv2\n","\n","#Numpy - numeric library\n","import numpy as np\n","\n","#Plotting\n","import matplotlib.pyplot as plt\n","\n","#This way it doesn't try to open a window un the GUI - works in python notebook\n","%matplotlib inline\n","\n","# Read image\n","img = cv2.imread(\"Lena.png\")\n","\n","# Create figure and show\n","plt.figure(figsize=(6,6))\n","plt.imshow(img)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TQaTEDfqhj-4","colab_type":"text"},"cell_type":"markdown","source":["### Color space conversions"]},{"metadata":{"id":"bUfm5YwlhrlG","colab_type":"code","colab":{}},"cell_type":"code","source":["#OpenCV uses BGR by default. This is why the colors look wrong\n","# So we convert it to RGB\n","img_rgb = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n","\n","# We also create a grayscale version\n","img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","\n","# Figure with subplots\n","plt.figure(figsize=(10,10))\n","plt.subplot(1,2,1)\n","plt.imshow(img_rgb)\n","plt.subplot(1,2,2)\n","plt.imshow(img_gray,cmap='gray')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VQ4MXmr1iZuJ","colab_type":"text"},"cell_type":"markdown","source":["### Thresholding"]},{"metadata":{"id":"KkhCETV-iceU","colab_type":"code","colab":{}},"cell_type":"code","source":["# Thresholding with 3 different threshold values\n","# _,ret = function() means that we only care about the second return value\n","_,img_bin = cv2.threshold(img_gray,127,255,cv2.THRESH_BINARY)\n","_,img_bin2 = cv2.threshold(img_gray,50,255,cv2.THRESH_BINARY)\n","_,img_bin3 = cv2.threshold(img_gray,200,255,cv2.THRESH_BINARY)\n","\n","# Plotting\n","plt.figure(figsize=(20,20))\n","plt.subplot(1,3,1)\n","plt.imshow(img_bin,cmap='gray')\n","plt.subplot(1,3,2)\n","plt.imshow(img_bin2,cmap='gray')\n","plt.subplot(1,3,3)\n","plt.imshow(img_bin3,cmap='gray')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cUu8PPUekuzI","colab_type":"text"},"cell_type":"markdown","source":["### Histogram and equalization"]},{"metadata":{"id":"mj8Kd4Z_kydJ","colab_type":"code","colab":{}},"cell_type":"code","source":["# Compute histogram\n","hist = cv2.calcHist([img_gray],[0],None,[256],[0,256])\n","\n","# Equalize hitogram and recompute\n","img_eq = cv2.equalizeHist(img_gray)\n","hist2 = cv2.calcHist([img_eq],[0],None,[256],[0,256])\n","\n","# Plotting\n","plt.figure(figsize=(25,10))\n","plt.subplot(2,2,1)\n","plt.imshow(img_gray,cmap='gray')\n","plt.subplot(2,2,2)\n","plt.bar(np.arange(256),hist[:,0])\n","plt.subplot(2,2,3)\n","plt.imshow(img_eq,cmap='gray')\n","plt.subplot(2,2,4)\n","plt.bar(np.arange(256),hist2[:,0])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qgyxAMzwmrYT","colab_type":"text"},"cell_type":"markdown","source":["### Filtering\n","#### Add noise"]},{"metadata":{"id":"Nq0AQp78mtV7","colab_type":"code","colab":{}},"cell_type":"code","source":["# Add noise to the image\n","def noisy(noise_typ,image):\n","    if noise_typ == \"gauss\":\n","        row,col= image.shape\n","        mean = 0\n","        sigma = 15\n","        # Create random gaussian\n","        gauss = np.random.normal(mean,sigma,(row,col))\n","        # Make sure it has the same shape\n","        gauss = gauss.reshape(row,col)\n","        noisy = image + gauss\n","        return noisy\n","    elif noise_typ == \"snp\":\n","        row,col = image.shape\n","        s_vs_p = 0.5\n","        amount = 0.02\n","        out = np.copy(image)\n","        # Number of salt (half of total)\n","        num_salt = np.ceil(amount * image.size * s_vs_p)\n","        # Random locations\n","        coords = [np.random.randint(0, i - 1, int(num_salt)) for i in image.shape]\n","        out[coords] = 255\n","\n","        # Number of pepper (half of total)\n","        num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n","        # Random locations\n","        coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in image.shape]\n","        out[coords] = 0\n","        return out"],"execution_count":0,"outputs":[]},{"metadata":{"id":"I6if7OMvnMxa","colab_type":"text"},"cell_type":"markdown","source":["#### Create images"]},{"metadata":{"id":"4swLa1conOf9","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create noisy images\n","img_gauss = noisy(\"gauss\",img_gray)\n","img_snp = noisy(\"snp\",img_gray)\n","\n","plt.figure(figsize=(15,15))\n","plt.subplot(1,2,1)\n","plt.imshow(img_gauss,cmap='gray')\n","plt.subplot(1,2,2)\n","plt.imshow(img_snp,cmap='gray')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1nl6CqziokGj","colab_type":"text"},"cell_type":"markdown","source":["#### Filter Images"]},{"metadata":{"id":"3PyvoWHbolyE","colab_type":"code","colab":{}},"cell_type":"code","source":["# Do gaussian and median filtering\n","# EXERCISE: Play around with the filter types and sizes\n","img_gfilt = cv2.GaussianBlur(img_gauss,(3,3),0)\n","img_mfilt = cv2.medianBlur(img_snp,3)\n","\n","plt.figure(figsize=(15,15))\n","plt.subplot(1,2,1)\n","plt.imshow(img_gfilt,cmap='gray')\n","plt.subplot(1,2,2)\n","plt.imshow(img_mfilt,cmap='gray')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E1cXCX-SAhDI","colab_type":"text"},"cell_type":"markdown","source":["## Fourier Transform"]},{"metadata":{"id":"gHwLIdPXAc1A","colab_type":"code","colab":{}},"cell_type":"code","source":["# Compute 2D FFT and shift the zero frequency to the center\n","f = np.fft.fft2(img_gray)\n","fshift = np.fft.fftshift(f)\n","\n","# Copies for filtering\n","fshift_filter = fshift.copy()\n","fshift_filter2 = fshift.copy()\n","\n","# Compute center coordinates (zero frequency)\n","center = fshift_filter.shape[0] // 2, fshift_filter.shape[1] // 2\n","\n","# Ideal high pass filter\n","fshift_filter[center[0]-20:center[0]+20,center[1]-20:center[1]+20] = 0\n","\n","# Ideal low pass filter\n","fshift_filter2[0:center[0]-20,:] = 0\n","fshift_filter2[center[0]+20:,:] = 0\n","fshift_filter2[:,0:center[1]-20] = 0\n","fshift_filter2[:,center[1]+20:] = 0\n","\n","# Shift back, then inverse FFT (np.abs makes sure that the image is real)\n","f_filter = np.fft.ifftshift(fshift_filter)\n","img_filter = np.abs(np.fft.ifft2(f_filter))\n","f_filter2 = np.fft.ifftshift(fshift_filter2)\n","img_filter2 = np.abs(np.fft.ifft2(f_filter2))\n","\n","# Transform for better visualization\n","magnitude_spectrum = 20*np.log(np.abs(fshift))\n","magnitude_spectrum_filt = 20*np.log(np.abs(fshift_filter)+1)\n","magnitude_spectrum_filt2 = 20*np.log(np.abs(fshift_filter2)+1)\n","\n","plt.figure(figsize=(25,15))\n","plt.subplot(2,3,1)\n","plt.imshow(img_gray,cmap='gray')\n","plt.subplot(2,3,2)\n","plt.imshow(img_filter,cmap='gray')\n","plt.subplot(2,3,3)\n","plt.imshow(img_filter2,cmap='gray')\n","plt.subplot(2,3,4)\n","plt.imshow(magnitude_spectrum,cmap='gray')\n","plt.subplot(2,3,5)\n","plt.imshow(magnitude_spectrum_filt,cmap='gray')\n","plt.subplot(2,3,6)\n","plt.imshow(magnitude_spectrum_filt2,cmap='gray')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FZAqNDKzpQL-","colab_type":"text"},"cell_type":"markdown","source":["## Feature detection\n","\n","### Edges\n","\n","#### Sobel and Laplace"]},{"metadata":{"id":"ebRlQMhRpXeE","colab_type":"code","colab":{}},"cell_type":"code","source":["# Zero in second arguments means grayscale\n","featImg = cv2.imread(\"sudoku-original.jpg\",0)\n","\n","# Compute filtered values\n","laplacian = np.absolute(cv2.Laplacian(featImg,cv2.CV_64F))\n","sobelx = np.absolute(cv2.Sobel(featImg,cv2.CV_64F,1,0,ksize=5))\n","sobely = np.absolute(cv2.Sobel(featImg,cv2.CV_64F,0,1,ksize=5))\n","\n","plt.figure(figsize=(15,15))\n","plt.subplot(2,2,1)\n","plt.imshow(featImg,cmap='gray')\n","plt.subplot(2,2,2)\n","plt.imshow(laplacian,cmap='gray')\n","plt.subplot(2,2,3)\n","plt.imshow(sobelx,cmap='gray')\n","plt.subplot(2,2,4)\n","plt.imshow(sobely,cmap='gray')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Rrp8E250F8z_","colab_type":"text"},"cell_type":"markdown","source":["### Canny and Hough\n","\n"]},{"metadata":{"id":"X3AZYW_JF7C4","colab_type":"code","colab":{}},"cell_type":"code","source":["# Run Canny\n","# EXERCISE: Play around with the thresholds\n","edges = cv2.Canny(featImg,50,120)\n","\n","# Run Hough transform\n","# Second and third arguments are the resolution of r and theta\n","# Fourth argument is the amount of votes needed for a positive line detection\n","lines = cv2.HoughLines(edges,1,np.pi/180,150)\n","\n","# Draw lines on the image\n","lineIm = cv2.cvtColor(featImg,cv2.COLOR_GRAY2BGR)\n","\n","for line in lines:\n","    rho,theta = line[0]\n","    a = np.cos(theta)\n","    b = np.sin(theta)\n","    x0 = a*rho\n","    y0 = b*rho\n","    x1 = int(x0 + 1000*(-b))\n","    y1 = int(y0 + 1000*(a))\n","    x2 = int(x0 - 1000*(-b))\n","    y2 = int(y0 - 1000*(a))\n","    cv2.line(lineIm,(x1,y1),(x2,y2),(255,0,0),2)\n","\n","plt.figure(figsize=(25,25))\n","plt.subplot(1,3,1)\n","plt.imshow(featImg,cmap='gray')\n","plt.subplot(1,3,2)\n","plt.imshow(edges,cmap='gray')\n","plt.subplot(1,3,3)\n","plt.imshow(lineIm,cmap='gray')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"d3wbV5nfKqVz","colab_type":"text"},"cell_type":"markdown","source":["### Template Matching"]},{"metadata":{"id":"ilTPxcQeKsfh","colab_type":"code","colab":{}},"cell_type":"code","source":["# Load image and template\n","mario_rgb = cv2.imread('mario.jpg')\n","mario_gray = cv2.cvtColor(mario_rgb, cv2.COLOR_BGR2GRAY)\n","template = cv2.imread('mario_template.jpg',0)\n","w, h = template.shape[::-1]\n","   \n","# Run template matching\n","res = cv2.matchTemplate(mario_gray,template,cv2.TM_CCOEFF_NORMED)\n","\n","# Get locations where the correlation is larger than the threshold\n","threshold = 0.8\n","loc = np.where( res >= threshold)\n","\n","# Draw\n","for pt in zip(*loc[::-1]):\n","    cv2.rectangle(mario_rgb, pt, (pt[0] + w, pt[1] + h), (0,0,255), 2)\n","    \n","mario_rgb = cv2.cvtColor(mario_rgb, cv2.COLOR_BGR2RGB)\n","plt.figure(figsize=(10,10))\n","plt.imshow(mario_rgb)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-uxgtF1tLuKV","colab_type":"text"},"cell_type":"markdown","source":["### ORB Keypoint Matching"]},{"metadata":{"id":"BZc_HkypLyA1","colab_type":"code","colab":{}},"cell_type":"code","source":["img1 = cv2.imread('box.jpg',0)          # queryImage\n","img2 = cv2.imread('box_in_scene.png',0) # trainImage\n","    \n","# Initiate ORB detector\n","orb = cv2.ORB_create()\n","    \n","# find the keypoints and descriptors with ORB\n","kp1, des1 = orb.detectAndCompute(img1,None)\n","kp2, des2 = orb.detectAndCompute(img2,None)\n","\n","# BFMatcher with default params Note: Hamming distance\n","bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n","\n","# Find the two best matches for every keypoint\n","matches = bf.knnMatch(des1,des2, k=2)\n","\n","# Apply ratio test: the the best match is much better \n","# than the second best, we keep the match\n","good = []\n","for m,n in matches:\n","    if m.distance < 0.75*n.distance:\n","        good.append([m])\n","    \n","# cv2.drawMatchesKnn expects list of lists as matches.\n","img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,good,None,flags=2)\n","\n","plt.figure(figsize=(20,20))\n","plt.imshow(img3)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hnTgjtz-Rh3x","colab_type":"text"},"cell_type":"markdown","source":["## Binary Images\n","\n","### Erosion, dilation"]},{"metadata":{"id":"Iheq3nERRpTC","colab_type":"code","colab":{}},"cell_type":"code","source":["j_img = cv2.imread('j.png',0)\n","\n","# Create structuring element\n","kernel = np.ones((5,5),np.uint8)\n","\n","# EXERCISE: see the effect of the number of iterations\n","erosion = cv2.erode(j_img,kernel,iterations = 1)\n","dilation = cv2.dilate(j_img,kernel,iterations = 1)\n","\n","plt.figure(figsize=(15,15))\n","plt.subplot(1,3,1)\n","plt.imshow(j_img,cmap='gray')\n","plt.subplot(1,3,2)\n","plt.imshow(erosion,cmap='gray')\n","plt.subplot(1,3,3)\n","plt.imshow(dilation,cmap='gray')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HKdmQ_faSaUr","colab_type":"text"},"cell_type":"markdown","source":["### Opening, Closing"]},{"metadata":{"id":"5hloirGTSZxz","colab_type":"code","colab":{}},"cell_type":"code","source":["opening = cv2.imread('opening.png',0)\n","closing = cv2.imread('closing.png',0)\n","\n","opened = cv2.morphologyEx(opening, cv2.MORPH_OPEN, kernel)\n","closed = cv2.morphologyEx(closing, cv2.MORPH_CLOSE, kernel)\n","\n","plt.figure(figsize=(20,10))\n","plt.subplot(2,2,1)\n","plt.imshow(opening,cmap='gray')\n","plt.subplot(2,2,2)\n","plt.imshow(opened,cmap='gray')\n","plt.subplot(2,2,3)\n","plt.imshow(closing,cmap='gray')\n","plt.subplot(2,2,4)\n","plt.imshow(closed,cmap='gray')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D758aEJzTiE5","colab_type":"text"},"cell_type":"markdown","source":["## Coin Segmentation using marker watershed\n","\n","### Threshold"]},{"metadata":{"id":"q5_d7pm3Tpwb","colab_type":"code","colab":{}},"cell_type":"code","source":["coin_img = cv2.imread('water_coins.jpg')\n","coin_gray = cv2.cvtColor(coin_img,cv2.COLOR_BGR2GRAY)\n","\n","# OTSU is an adaptive thresholding method\n","ret, thresh = cv2.threshold(coin_gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n","\n","plt.figure(figsize=(7,7))\n","plt.imshow(thresh,cmap='gray')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rvPFwZDlUl-3","colab_type":"text"},"cell_type":"markdown","source":["### Eroision to extract sure foreground area"]},{"metadata":{"id":"PqS4vBADUp95","colab_type":"code","colab":{}},"cell_type":"code","source":["# Erosion gives us a binary image that is certainly foreground\n","sure_fg = cv2.erode(thresh,kernel,iterations=7)\n","\n","# Erosion gives us a binary image that is certainly background\n","sure_bg = cv2.dilate(thresh,kernel,iterations=2)\n","\n","# Uncertain region\n","unknown = cv2.subtract(sure_bg,sure_fg)\n","\n","plt.figure(figsize=(7,7))\n","plt.imshow(sure_fg,cmap='gray')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rej2M3TeVBDQ","colab_type":"text"},"cell_type":"markdown","source":["### Connected components to label foreground pieces"]},{"metadata":{"id":"5ELN6jRiVFNP","colab_type":"code","colab":{}},"cell_type":"code","source":["# Label separate foreground pathes\n","ret, markers = cv2.connectedComponents(sure_fg)\n","     \n","# Add one to all labels so that sure background is not 0, but 1\n","markers = markers+1\n","     \n","# Now, mark the region of unknown with zero\n","markers[unknown==255] = 0\n","\n","plt.figure(figsize=(7,7))\n","plt.imshow(markers)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9Xa5v_UxVjjT","colab_type":"text"},"cell_type":"markdown","source":["### Run Watershed"]},{"metadata":{"id":"xHOAm3ZUVlbF","colab_type":"code","colab":{}},"cell_type":"code","source":["# Runwatershed\n","markers = cv2.watershed(coin_img,markers)\n","\n","# Red out the boundaries\n","coin_img[markers == -1] = [255,0,0]\n","\n","plt.figure(figsize=(15,15))\n","plt.subplot(1,2,1)\n","plt.imshow(markers)\n","plt.subplot(1,2,2)\n","plt.imshow(coin_img)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Jcu_GzjAXoUW","colab_type":"text"},"cell_type":"markdown","source":["## Video Analytics\n","### Create progress bar"]},{"metadata":{"id":"ge99jTs3cDkx","colab_type":"code","colab":{}},"cell_type":"code","source":["from IPython.display import HTML, display\n","\n","def progress(value, max=100):\n","    return HTML(\"\"\"\n","        <progress\n","            value='{value}'\n","            max='{max}',\n","            style='width: 100%'\n","        >\n","            {value}\n","        </progress>\n","    \"\"\".format(value=value, max=max))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"99a8O9TVcD3q","colab_type":"text"},"cell_type":"markdown","source":["### Optical Flow"]},{"metadata":{"id":"f2pweNseXtiB","colab_type":"code","colab":{}},"cell_type":"code","source":["# Read input video and get number of frames\n","cap = cv2.VideoCapture(\"vtest.avi\")\n","length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","     \n","# Read first frame\n","ret, frame1 = cap.read()\n","prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n","\n","# Initialize HSV image (this will be used to visualize the optical flow)\n","hsv = np.zeros_like(frame1)\n","# Saturation is fixed to maximum\n","hsv[...,1] = 255\n","\n","# Iinitialize the output video\n","frame_height,frame_width = prvs.shape\n","out = cv2.VideoWriter('optflow.mp4',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width*2,frame_height))\n","\n","# Start progress bar\n","cntr = 0\n","bar = display(progress(cntr, length), display_id=True)\n","     \n","while(1):\n","    \n","    # Return once we no longer get frames\n","    ret, frame2 = cap.read()\n","    if not ret:\n","        break\n","        \n","    # Update next frame\n","    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n","\n","    # Run Farneback optical flow\n","    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n","\n","    # Convert x,y optical flow to polar coordinates\n","    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n","    \n","    # Direction will become the Hue, magnitude will be the Value\n","    hsv[...,0] = ang*180/np.pi/2\n","    hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n","    \n","    # Convert back for visualization\n","    bgr = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n","    \n","    # Put the original video and the optical flow side-by-side and write\n","    frame = np.concatenate((frame2,bgr),1)\n","    out.write(frame)\n","    \n","    # Update previous frame and progress bar\n","    prvs = next\n","    cntr += 1\n","    bar.update(progress(cntr, length))\n","\n","# Clean up\n","cap.release()\n","out.release()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tYfAQZ5_f3XX","colab_type":"text"},"cell_type":"markdown","source":["### Background Subtraction"]},{"metadata":{"id":"KZ9kMz-_f6XU","colab_type":"code","colab":{}},"cell_type":"code","source":["# Read input video and get number of frames\n","cap = cv2.VideoCapture(\"vtest.avi\")\n","length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","     \n","# Read first frame\n","ret, frame1 = cap.read()\n","\n","# Iinitialize the output video\n","frame_height,frame_width,_ = frame1.shape\n","out = cv2.VideoWriter('bg.mp4',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width*2,frame_height))\n","\n","# Create Gaussian background subtractor\n","fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n","\n","# Start progress bar\n","cntr = 0\n","bar = display(progress(cntr, length), display_id=True)\n","     \n","while(1):\n","    # Return once we no longer get frames\n","    ret, frame2 = cap.read()\n","    if not ret:\n","        break\n","        \n","    # Apply subtraction\n","    fgmask = fgbg.apply(frame2)\n","    \n","    # Convert back for visualization\n","    bgr = cv2.cvtColor(fgmask,cv2.COLOR_GRAY2BGR)\n","    \n","    # Put the original video and the optical flow side-by-side and write\n","    frame = np.concatenate((frame2,bgr),1)\n","    out.write(frame)\n","    \n","    # Update previous frame and progress bar\n","    cntr += 1\n","    bar.update(progress(cntr, length))\n","\n","# Clean up\n","cap.release()\n","out.release()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"LqVyP64UlsHM","colab_type":"text"},"cell_type":"markdown","source":["## Download video files\n","To download the created videos, click the ![alt text](http://3dmr.iit.bme.hu/edu/DL/icon.png) icon on the top left, then select the files tab. From there, right click **optflow.mp4** and **bg.mp4** to download them to your computer."]}]}